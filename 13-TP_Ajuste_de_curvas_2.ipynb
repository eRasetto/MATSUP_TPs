{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N°10 - Descenso de gradiente\n",
    "Cuando nos encontramos en la situacion de tener que encontrar el minimo global o local de una función no convexa, los metodos para buscar raices vistos hasta el momento no aseguran una convergencia glabal. En estas situaciones, es mejor utilizar metodos de descenso/ascenso de grandientes.\n",
    "\n",
    "## Descenso de gradiente (Gradient Descent)\n",
    "Para optimizar modelos predictivos, tanto para clasificación, como así también para regresión. Uno de los métodos mas difundidos es **Descenso de Gradiente (Gradient Descent)**.\n",
    "\n",
    "El descenso de gradiente es un algoritmo de optimización iterativa de primer orden para encontrar un mínimo local de una función. Para realizar esto, se dan pasos proporcionales al negativo del gradiente (o gradiente aproximado) de la función en el punto actual. Si, en cambio, uno toma pasos proporcionales al positivo del gradiente, uno se aproxima a un máximo local de esa función; este ultimo procedimiento se conoce como ascenso de gradiente.\n",
    "\n",
    "El método de descenso de gradiente esta basado en la observación de una función $F(x)$ multi-variable que sea definida y diferenciable en la cercanía de un punto $a$. Evaluando el grandiente en el punto $a_n$ se puede estimar un nuevo valor $a_{n+1}$ donde se minimize $F(x)$. Esto es:\n",
    "$$a_{n+1}=a_n - \\eta\\nabla F(a_n)$$\n",
    "para un $\\eta$ suficientemente pequeño, se puede asegurar que $F(a_n)\\geq F(a_{n+1})$.\n",
    "\n",
    "Entonces, asumiendo un mínimo local inicial $a_0$ de $F(x)$, podemos ir descendiendo iterativamente a través de los distintos $a_0,a_1,a_2,\\dots$ donde $F(a_0)\\geq F(a_1)\\geq F(a_2)\\geq\\dots$ hasta encontrar un $x_n\\mid n\\geq 0$ que converge al mínimo local deseado.\n",
    "\n",
    "![gradient_descent](img/12-gradient_descent.gif)\n",
    "\n",
    "Un elemento clave en este método es determinar un correcto valor de $\\eta$. Si el valor de $\\eta$ es muy pequeño, el método va a requerir muchas iteraciones para converger, puede quedar atrapado en mínimos locales y nunca alcanzar un mínimo global. Al contrario, si el $\\eta$ es muy grande, el método puede sufrir oscilaciones permanentes y diverger.\n",
    "\n",
    "Otro punto muy importante, es determinar un buen punto inicial $a_0$ para el método. Dependiendo del punto inicial elegido, el método puede converger a resultados muy distintos.\n",
    "\n",
    "![gd_multiple_local_minimum](img/12-gd_multiple_local_minimum.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de costo (Loss Function)\n",
    "Una *función de costo* (o *Loss Function* en ingles) es una función que mapea un evento o valores de una o más variables en un número real que representa intuitivamente algún \"costo\" asociado con el evento. Un problema de optimización busca minimizar una función de costo. Una función objetivo es una función de costo o su negativa (en dominios específicos, llamada función de recompensa, función de utilidad, función de utilidad, función de adecuación, etc.), en cuyo caso se debe maximizar su valor.\n",
    "\n",
    "Una funcion de costo puede tener la siguiente forma:\n",
    "\n",
    "### Error Cuadratico Medio (MSE)\n",
    "\n",
    "$\\ell(w)\\triangleq\\;\\frac{1}{N}\\;\\sum_{i=1}^N\\;[y_i - \\hat{f}(x_i, w)]^2$ (*Error Cuadratico Medio* - MSE)\n",
    "\n",
    "Donde:\n",
    "* $N$ es el numero de muestras/elementos del dataset.\n",
    "* $y_i$ es el valor real/etiqueta de la muestra i del dataset.\n",
    "* $\\hat{f}(x_i, w)$ es la prediccion generada por $\\hat{f}$ dado el punto $x_i$ y los parametros del modelo $w$.\n",
    "\n",
    "En notación vectorial:\n",
    "\n",
    "$y=\\begin{pmatrix}y_1 \\\\ \\vdots \\\\ y_N \\end{pmatrix}$\n",
    "$X=\\begin{pmatrix}x_1^1 \\cdots x_k^1 \\cdots x_K^1 \\\\ \\vdots \\\\ x_1^N \\cdots x_k^N \\cdots x_K^N \\end{pmatrix}$\n",
    "$w=\\begin{pmatrix}w_1 \\\\ \\vdots \\\\ w_k \\\\ \\vdots \\\\ w_K \\end{pmatrix}$\n",
    "\n",
    "$e=y-Xw$\n",
    "\n",
    "**Función de costo expresada vectorialmente**\n",
    "\n",
    "$\\ell(w)\\triangleq\\;e^Te=(y-Xw)^T(y-Xw)$\n",
    "\n",
    "**Derivada de la Función de costo expresada vectorialmente**\n",
    "\n",
    "$\\nabla\\ell(w)=X^TXw-X^Ty=\\sum_{i=1}^Nx_i(w^Tx_i-y_i)$\n",
    "\n",
    "Esta función de costo, utilizada  en conjunto con *Descenso de gradiente*, nos permite encontrar modelos (Valores del vector *w*) que representen modelos lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logistica (Logistic Regression)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
